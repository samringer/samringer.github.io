---
layout: post
title:  "Generative Modelling With U-Nets"
date:   2018-10-05 20:00:00 +0200
permalink: /u_nets/
mathjax: true
---

This post is a breakdown of [*A Variational U-Net for Conditional Appearance and Shape Generation.*](https://arxiv.org/pdf/1804.04694.pdf)

### Aims

It's no secret that generative modelling has come a long way in recent years: the best GANs can generate photorealistic images for [every ImageNet category](https://arxiv.org/pdf/1610.09585.pdf). However, most generative models aim to generate an image directly. This means it has not been possible to control image characteristic like shape and appearance separately. When generating images of people, *shape* refers to the geometrical layout that the person is in *(sitting, running etc.)* whilst *appearance* refers to the colour and texture present in the image *(red trousers, blond hair etc.)*. Controlling shape and appearance independently has so far not been possible in generative modelling.

For instance, it has not been possible to generate and image conditioned on "*Generate an image of a man kicking a football (**shape**) wearing a pinstripe suit (**appearance**)*". The overall aim of this paper is to take *Picture A* and *Picture B* and produce a third picture, *Picture C*, that has *Picture A*'s shape and *Picture B*'s appearance.

INSERT SOME IMAGES HERE

For a deeper analysis, we need to write our above goal with some mathematical notation. First of all, let's define some variables:

$x$ - The variable representing our generated image

$y$ - The variable representing the desired shape of our generated image

$z$ - The variable representing the desired appearance of our generated image

Now we have our basic variables, the overall goal of the paper is to learn a probability distribution: $p(x|y,z)$

More verbosely, the probability distribution $p(x|y,z)$ says that, for any given appearance and shape, how likely is a given image $x$. An image that shows similar shape and appearance to those encoded by $y$ and $z$ will have a high probability whereas a random image will likely have a very low probability. 

If we learn $p(x|y,z)$ well then we can use it directly as an image generator. If we have a given $y$ and $z$ then the $x$ that maximises the probability distribution will be a generated image that has both the desired shape and appearance that we are after! Mathmatically, our best generated image is: $\text{arg max}_x p(x|y,z)$

















Aim: to model/generate shape and appearance orthogonally? (bad choice of word)

Disentagnling of x and y

y estimated from the joint algorithm thing

Vanilla VAEs and why they don't work

Go over log likelihood vs probability

ELBO = difference between distribution of a latent variable and distribution of respective observed variable

?Intractable integral means no closed form and high dimensional so we can't solve numerically?

Talk about the maths behind the encoder and decoder.

Say that this: https://blog.evjang.com/2016/08/variational-bayes.html should be read first but maybe just rehash the most important bits.

Estimate y and use that estimate with the original image to estimate z. Done by maximising conditional log-likilihood ($log P(x|\hat{y})$)

The thing we are interested in for generative modelling is $P(X|Z)$ (<- is the liklihood. Z is cat label, X is image)

Talk about intractability

You sample probability dists and compute PDFs.

*Sampling* $z \sim Q(Z|X)$ is 'encoding' that converts observation $x$ to latent code $z$

*Sampling* $ x \sim Q(X|Z) $ is 'decoding' that reconstructs inputs from latents $z$

Variational lower bound is computationally tractable if you can evaluate $p(x|z), p(x), q(z|x)$ 

OVERALL GOAL OF PAPER IS TO SEPARATELY ALTER SHAPE AND APPEARANCE (as VAE can't disentangle y and z it would fail to meet the goal of the paper).

Conditional VAE: aims to infer z from (image and estimate of y)

First step is to separate shape from appearance. Know image, estimate y, use these to find z.

Equation 3 is our loss function

Explain Unets



Step 1: Explain goal at high level

Step 2: Explain goal with a bit of maths

Step 3: Explain with some maths why VAE won't word

Step 4: Explain actual approach at high level

Step 5: Explain actual approach with maths