---
layout: post
title:  "Generative Modelling With U-Nets"
date:   2018-10-05 20:00:00 +0200
permalink: /u_nets/
mathjax: true
---

Aim: to model/generate shape and appearance orthogonally? (bad choice of word)

Disentagnling of x and y

y estimated from the joint algorithm thing

Vanilla VAEs and why they don't work

Go over log likelihood vs probability

ELBO = difference between distribution of a latent variable and distribution of respective observed variable

?Intractable integral means no closed form and high dimensional so we can't solve numerically?

Talk about the maths behind the encoder and decoder.

Say that this: https://blog.evjang.com/2016/08/variational-bayes.html should be read first but maybe just rehash the most important bits.

Estimate y and use that estimate with the original image to estimate z. Done by maximising conditional log-likilihood ($log P(x|\hat{y})$)

The thing we are interested in for generative modelling is $P(X|Z)$ (<- is the liklihood. Z is cat label, X is image)

Talk about intractability

You sample probability dists and compute PDFs.

*Sampling* $z \sim Q(Z|X)$ is 'encoding' that converts observation $x$ to latent code $z$

*Sampling* $ x \sim Q(X|Z) $ is 'decoding' that reconstructs inputs from latents $z$

Variational lower bound is computationally tractable if you can evaluate $p(x|z), p(x), q(z|x)$ 

OVERALL GOAL OF PAPER IS TO SEPARATELY ALTER SHAPE AND APPEARANCE (as VAE can't disentangle y and z it would fail to meet the goal of the paper).

Conditional VAE: aims to infer z from (image and estimate of y)

First step is to separate shape from appearance. Know image, estimate y, use these to find z.

Equation 3 is our loss function

Explain Unets



Step 1: Explain goal at high level

Step 2: Explain goal with a bit of maths

Step 3: Explain with some maths why VAE won't word

Step 4: Explain actual approach at high level

Step 5: Explain actual approach with maths